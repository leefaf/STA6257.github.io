---
title: "Literature Review"
subtitle: "Topic: Principal Component Analysis"
author: "Brandy Carr (bjc57)"
date: "Fall 2022"
output:
  html_document:
    df_print: paged
    highlight: pygments
course: STA6257 (Advance Statistical Modeling)
#bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
---


<style>
 .title {
    color: #191970;    
  }
 .subtitle {
    color: #191970;
  }
  .author {
    color: #191970;
}
 .date {
    color: #191970;
  }
 body {
    background-color: #FAFAF5;
  }
</style>

<hr />
### <span style="color: #8B814C;">**Introduction**</span>

<span style="color: #8B814C;">
Kernel regression is a non-parametric estimator that estimates the conditional expectation of two variables which is random. The goal of a kernel regression is to discover the non-linear relationship between two random variables. To discover the non-linear relationship, kernel estimator or kernel smoothing is the main method to estimate the curve for non-parametric
statistics. In kernel estimator, weight function is known as kernel function [@efr2008]. 
</span>

<hr />
### <span style="color: #8B814C;">**Methods**</span>

<span style="color: #8B814C;">
The common non-parametric regression model is $Y_i = m(X_i) + \varepsilon_i$, where
$Y_i$ can be defined as the sum of the regression function value $m(x)$ for $X_i$.
Here $m(x)$ is unknown and $\varepsilon_i$ some errors. With the help of this definition, we can create the estimation for
local averaging i.e. $m(x)$ can be estimated with the product of $Y_i$ average
and $X_i$ is near to $x$. In other words, this means that we are discovering
the line through the data points with the help of surrounding data points.
The estimation formula is printed below [@R-base]:
<span style="color: #8B814C;">
$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$
$W_n(x)$ is the sum of weights that belongs to all real numbers. Weights
are positive numbers and small if $X_i$ is far from $x$.
</span></span>

<hr />
### <span style="color: #8B814C;">**Analysis and Results**</span>

<hr />
### <span style="color: #8B814C;">**Data and Vizualisation**</span>

<span style="color: #8B814C;">
A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r, fig1, fig.height=6, fig.width=12, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_wsj()
```

</span>

<hr />
### <span style="color: #8B814C;">**Statistical Modeling**</span>

<hr />
### <span style="color: #8B814C;">**Conclusion**</span>

<hr />
## <span style="color: #191970;">References</span>

